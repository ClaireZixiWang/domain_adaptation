{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578648c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.utils.data as torchdata\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from train_model import train_model\n",
    "# from test_model import test_model\n",
    "%matplotlib inline\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea3abfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bef3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american-flag\n"
     ]
    }
   ],
   "source": [
    "filePath = '/local/rcs/ll3504/datasets/256_ObjectCategories/'\n",
    "namelist = os.listdir(filePath)\n",
    "nameDic_cal = {}\n",
    "for name in namelist:\n",
    "    splits = name.split(\".\")\n",
    "    nameDic_cal[int(splits[0])-1] = splits[1]\n",
    "print(nameDic_cal[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af7d1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path='/database', dataset_name='caltech-256-common'):\n",
    "    # No holdout testing data. train and test data are the same, but different transformation\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "#             transforms.Resize([256, 256]),\n",
    "#             transforms.RandomCrop(224),\n",
    "#             transforms.RandomRotation(20),\n",
    "#             transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "#             transforms.Resize([224, 224]),\n",
    "#             transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    tr_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['train'])\n",
    "    te_dataset = datasets.ImageFolder(path + dataset_name + '/', data_transforms['test'])\n",
    "#     print('{} train set size: {}'.format(dataset_name, len(tr_dataset)))\n",
    "#     print('{} test set size: {}'.format(dataset_name, len(te_dataset)))\n",
    "\n",
    "    return tr_dataset, te_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42856c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(train_dataset, test_dataset, valid_size=0.2, batch_size=128, train_size = 128):\n",
    "    '''\n",
    "    This function splits dataset into train, val, and test sets, and return train, val, test dataloaders.\n",
    "    Val and Test loaders are the same\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # what does the len function gives?\n",
    "    num_train = len(train_dataset)\n",
    "    # print(\"DEBUGGING: overall training data size =\", num_train)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:split+train_size], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    \n",
    "    # print(\"DEBUGGING: the train_ind are:\", len(train_idx))\n",
    "\n",
    "\n",
    "    train_loader = torchdata.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=True, sampler = train_sampler)\n",
    "    test_loader = torchdata.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=48, pin_memory=True, drop_last=True, sampler = valid_sampler)\n",
    "    dataloaders = {'train': train_loader,\n",
    "                   'val': test_loader,\n",
    "                   'test': test_loader}\n",
    "    dataset_sizes ={'train': train_size, #int(np.floor((1-valid_size) * num_train)),\n",
    "                    'val': int(np.floor(valid_size * num_train)),\n",
    "                    'test': int(np.floor(valid_size * num_train))}\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4078f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebase = '/local/rcs/ll3504/datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6f0d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "corruption = ['zoom_blur', 'speckle_noise', 'spatter',\n",
    "                       'snow', 'glass_blur', 'motion_blur', 'saturate',\n",
    "                       'gaussian_blur', 'frost', 'fog', 'brightness', 'contrast',\n",
    "                       'elastic_transform', 'pixelate', 'jpeg_compression', 'defocus_blur']\n",
    "weather  = ['snow', 'frost', 'fog', 'spatter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fadcb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imagenetc(imagebase, severity=1, batch_size=128, sample_size = 128):\n",
    "    '''\n",
    "    Returns:\n",
    "        ref_dataloaders:          ImageNet original validation data, as a reference\n",
    "        ref_dataset_sizes:        1000, not the sizes of the real dataset in the ref_loader, probs used downstream\n",
    "        corrupted_dataloaders:    A list of corrupted dataloaders, each element in a list represetns the data loaders\n",
    "                                  for one corruption type. Each element contains ['train']['val']['test'] loaders\n",
    "        corrupted_dataset_sizes:  A list of dictionaries of the sizes of each loaders for each corruption\n",
    "        corruption:               A list of corruption names, in the same order of the corrupted_dataloaders\n",
    "    '''\n",
    "    corruption = ['zoom_blur', 'speckle_noise', 'spatter',\n",
    "                       'snow', 'glass_blur', 'motion_blur', 'saturate',\n",
    "                       'gaussian_blur', 'frost', 'fog', 'brightness', 'contrast',\n",
    "                       'elastic_transform', 'pixelate', 'jpeg_compression', 'defocus_blur']\n",
    "    corrupted_dataloaders = []\n",
    "    corrupted_dataset_sizes = []\n",
    "    \n",
    "    # this is the imageNet validation data\n",
    "    imagenet_val = datasets.ImageNet(imagebase+'imagenetc/', split='val', transform=transforms.Compose([\n",
    "            transforms.Resize([224, 224]),\n",
    "            transforms.CenterCrop((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "                                   target_transform=None)#, download=False)\n",
    "    \n",
    "    # TODO: subsample some size of ImageNet training data as source\n",
    "        # Doesn't need this step\n",
    "#     print(\"DEBUGGING: imagenet_val size is:\", len(imagenet_val))\n",
    "    \n",
    "    random_indices = random.sample(range(0, len(imagenet_val)), int(len(imagenet_val)*0.02))\n",
    "#     print(\"DEBUGGING: random indices are:\", len(random_indices))\n",
    "    imagenet_val_subset = data.Subset(imagenet_val, random_indices)\n",
    "    val_loader = torch.utils.data.DataLoader(imagenet_val_subset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=48)\n",
    "    ref_dataloaders = { 'val': val_loader,\n",
    "                       'test': val_loader}\n",
    "    ref_dataset_sizes ={'val': int(len(val_loader.dataset)),\n",
    "                        'test': int(len(val_loader.dataset))}\n",
    "    \n",
    "    # for every type of corruption, go to the specified severity folder\n",
    "    for corr in corruption:\n",
    "        dataset_name = 'imagenetc/' + corr + '/' + str(severity)\n",
    "        # Get dataset from folder\n",
    "        corr_trian_images, corr_test_images = get_dataset(imagebase, dataset_name)\n",
    "        # get corruption-specific train, val, test loader\n",
    "        # train: training data, non-overlap with val/test\n",
    "        # val: non-overlap with train, same as test\n",
    "        # test: non-overlap with train, same as test\n",
    "        corr_dataloaders, corr_dataset_sizes = split_dataset(corr_trian_images, corr_test_images, valid_size=0.02, batch_size=batch_size, train_size=sample_size)\n",
    "        corrupted_dataloaders.append(corr_dataloaders)\n",
    "        corrupted_dataset_sizes.append(corr_dataset_sizes)\n",
    "    return ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee63c211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932860ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce63c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511b0390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "def get_dataset_loader(valdir, batch_size, shuffle):\n",
    "    val_dataset = datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ]))\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=shuffle\n",
    "    )\n",
    "    return val_loader\n",
    "\n",
    "def gce(logits, target, q = 0.8):\n",
    "    \"\"\" Generalized cross entropy.\n",
    "    \n",
    "    Reference: https://arxiv.org/abs/1805.07836\n",
    "    \"\"\"\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    probs_with_correct_idx = probs.index_select(-1, target).diag()\n",
    "    loss = (1. - probs_with_correct_idx**q) / q\n",
    "    return loss.mean()\n",
    "\n",
    "def adapt_batchnorm(model):\n",
    "    model.eval()\n",
    "    parameters = []\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, torch.nn.BatchNorm2d):\n",
    "            parameters.extend(module.parameters())\n",
    "            module.train()\n",
    "    return parameters\n",
    "\n",
    "\n",
    "# ---\n",
    "\n",
    "def evaluate(\n",
    "        datadir = '/data/imagenetc/gaussian_blur/3',\n",
    "        num_epochs = 5,\n",
    "        batch_size = 128,\n",
    "        learning_rate = 1e-3,\n",
    "        gce_q = 0.8\n",
    "    ):\n",
    "    \n",
    "    model = models.resnet50(pretrained = True).cuda()\n",
    "    parameters = adapt_batchnorm(model)\n",
    "    val_loader = get_dataset_loader(\n",
    "        datadir,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = True\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr = learning_rate\n",
    "    )\n",
    "    \n",
    "    num_correct, num_samples = 0., 0.\n",
    "    for epoch in range(num_epochs):\n",
    "        predictions = []\n",
    "        for images, targets in val_loader:\n",
    "\n",
    "            logits = model(images.cuda())\n",
    "            predictions = logits.argmax(dim = 1)\n",
    "            loss = gce(logits, predictions, q = gce_q)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            num_correct += (predictions.detach().cpu() == targets).float().sum()\n",
    "            num_samples += len(targets)\n",
    "        print(f\"Correct: {num_correct:#5.0f}/{num_samples:#5.0f} ({100 * num_correct / num_samples:.2f} %)\")\n",
    "        \n",
    "    return num_correct / num_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79626505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRUPTION: snow ; SEVERITY: 1\n",
      "Correct: 31750./50000. (63.50 %)\n",
      "Correct: 64426./100000. (64.43 %)\n",
      "Correct: 97530./150000. (65.02 %)\n",
      "Correct: 130809./200000. (65.40 %)\n",
      "Correct: 164196./250000. (65.68 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: snow ; SEVERITY: 2\n",
      "Correct: 25539./50000. (51.08 %)\n",
      "Correct: 53112./100000. (53.11 %)\n",
      "Correct: 81562./150000. (54.37 %)\n",
      "Correct: 110457./200000. (55.23 %)\n",
      "Correct: 139590./250000. (55.84 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: snow ; SEVERITY: 3\n",
      "Correct: 25887./50000. (51.77 %)\n",
      "Correct: 53676./100000. (53.68 %)\n",
      "Correct: 82304./150000. (54.87 %)\n",
      "Correct: 111390./200000. (55.69 %)\n",
      "Correct: 140780./250000. (56.31 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: snow ; SEVERITY: 4\n",
      "Correct: 21520./50000. (43.04 %)\n",
      "Correct: 45658./100000. (45.66 %)\n",
      "Correct: 70768./150000. (47.18 %)\n",
      "Correct: 96521./200000. (48.26 %)\n",
      "Correct: 122670./250000. (49.07 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: snow ; SEVERITY: 5\n",
      "Correct: 20534./50000. (41.07 %)\n",
      "Correct: 44086./100000. (44.09 %)\n",
      "Correct: 68722./150000. (45.81 %)\n",
      "Correct: 94054./200000. (47.03 %)\n",
      "Correct: 119781./250000. (47.91 %)\n",
      "---------------------------------------------------\n",
      "===============================================================\n",
      "CORRUPTION: frost ; SEVERITY: 1\n",
      "Correct: 32869./50000. (65.74 %)\n",
      "Correct: 66257./100000. (66.26 %)\n",
      "Correct: 99820./150000. (66.55 %)\n",
      "Correct: 133497./200000. (66.75 %)\n",
      "Correct: 167303./250000. (66.92 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: frost ; SEVERITY: 2\n",
      "Correct: 26912./50000. (53.82 %)\n",
      "Correct: 55215./100000. (55.22 %)\n",
      "Correct: 84025./150000. (56.02 %)\n",
      "Correct: 113052./200000. (56.53 %)\n",
      "Correct: 142243./250000. (56.90 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: frost ; SEVERITY: 3\n",
      "Correct: 22516./50000. (45.03 %)\n",
      "Correct: 46615./100000. (46.62 %)\n",
      "Correct: 71227./150000. (47.48 %)\n",
      "Correct: 95705./200000. (47.85 %)\n",
      "Correct: 119558./250000. (47.82 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: frost ; SEVERITY: 4\n",
      "Correct: 21619./50000. (43.24 %)\n",
      "Correct: 44907./100000. (44.91 %)\n",
      "Correct: 68520./150000. (45.68 %)\n",
      "Correct: 91535./200000. (45.77 %)\n",
      "Correct: 113848./250000. (45.54 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: frost ; SEVERITY: 5\n",
      "Correct: 18687./50000. (37.37 %)\n",
      "Correct: 38371./100000. (38.37 %)\n",
      "Correct: 57579./150000. (38.39 %)\n",
      "Correct: 76570./200000. (38.28 %)\n",
      "Correct: 95552./250000. (38.22 %)\n",
      "---------------------------------------------------\n",
      "===============================================================\n",
      "CORRUPTION: fog ; SEVERITY: 1\n",
      "Correct: 34844./50000. (69.69 %)\n",
      "Correct: 70064./100000. (70.06 %)\n",
      "Correct: 105517./150000. (70.34 %)\n",
      "Correct: 141079./200000. (70.54 %)\n",
      "Correct: 176589./250000. (70.64 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: fog ; SEVERITY: 2\n",
      "Correct: 33783./50000. (67.57 %)\n",
      "Correct: 68098./100000. (68.10 %)\n",
      "Correct: 102804./150000. (68.54 %)\n",
      "Correct: 137601./200000. (68.80 %)\n",
      "Correct: 172457./250000. (68.98 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: fog ; SEVERITY: 3\n",
      "Correct: 32125./50000. (64.25 %)\n",
      "Correct: 65136./100000. (65.14 %)\n",
      "Correct: 98494./150000. (65.66 %)\n",
      "Correct: 132131./200000. (66.07 %)\n",
      "Correct: 165883./250000. (66.35 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: fog ; SEVERITY: 4\n",
      "Correct: 30761./50000. (61.52 %)\n",
      "Correct: 62591./100000. (62.59 %)\n",
      "Correct: 94962./150000. (63.31 %)\n",
      "Correct: 127529./200000. (63.76 %)\n",
      "Correct: 160215./250000. (64.09 %)\n",
      "---------------------------------------------------\n",
      "CORRUPTION: fog ; SEVERITY: 5\n",
      "Correct: 26961./50000. (53.92 %)\n",
      "Correct: 55637./100000. (55.64 %)\n",
      "Correct: 85039./150000. (56.69 %)\n",
      "Correct: 114775./200000. (57.39 %)\n",
      "Correct: 144760./250000. (57.90 %)\n",
      "---------------------------------------------------\n",
      "===============================================================\n"
     ]
    }
   ],
   "source": [
    "severity = [1,2,3,4,5]\n",
    "results = np.zeros((3, 5))\n",
    "for cor_ind in range(3):\n",
    "    corr = weather[cor_ind]\n",
    "    for sev in severity:\n",
    "        print(\"CORRUPTION:\", corr, \"; SEVERITY:\", sev)\n",
    "        dataset_name = 'imagenetc/' + corr + '/' + str(sev)\n",
    "        result = evaluate(datadir=imagebase+dataset_name+'/')\n",
    "        results[cor_ind][sev-1] = result\n",
    "        print(\"---------------------------------------------------\")\n",
    "    print(\"===============================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dd308b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.656784  , 0.55835998, 0.56312001, 0.49068001, 0.47912401],\n",
       "       [0.66921198, 0.56897199, 0.478232  , 0.455392  , 0.38220799],\n",
       "       [0.70635599, 0.68982798, 0.66353202, 0.64086002, 0.57903999]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9a1491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4503864 , 0.48919681, 0.3440768 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-results.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03096a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7465ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7779dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the original experiment using the paper hyperparams\n",
    "\n",
    "base_cum_acc = np.zeros((5, len(corruption)))\n",
    "adapted_cum_acc = np.zeros((5, len(corruption)))\n",
    "\n",
    "\n",
    "acc_record_sev = {}\n",
    "batch_size = 96\n",
    "\n",
    "for severity in range(1, 6):\n",
    "    \n",
    "    acc_record_sev[severity] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b0262a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for severity = 1 corruption = snow\n",
      "Epoch 0\n",
      "Baseline Correct: 26716./48960. (54.57 %)\n",
      "Adapted Correct: 30224./48960. (61.73 %)\n",
      "Baseline Epoch Correct: 26716./48960. (54.57 %)\n",
      "Adapted Epoch Correct: 30224./48960. (61.73 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 53429./97920. (54.56 %)\n",
      "Adapted Correct: 61011./97920. (62.31 %)\n",
      "Baseline Epoch Correct: 26713./48960. (54.56 %)\n",
      "Adapted Epoch Correct: 30787./48960. (62.88 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 80149./146880. (54.57 %)\n",
      "Adapted Correct: 92202./146880. (62.77 %)\n",
      "Baseline Epoch Correct: 26720./48960. (54.58 %)\n",
      "Adapted Epoch Correct: 31191./48960. (63.71 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 106873./195840. (54.57 %)\n",
      "Adapted Correct: 123588./195840. (63.11 %)\n",
      "Baseline Epoch Correct: 26724./48960. (54.58 %)\n",
      "Adapted Epoch Correct: 31386./48960. (64.11 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 133595./244800. (54.57 %)\n",
      "Adapted Correct: 155255./244800. (63.42 %)\n",
      "Baseline Epoch Correct: 26722./48960. (54.58 %)\n",
      "Adapted Epoch Correct: 31667./48960. (64.68 %)\n",
      "Corrupt Val Adapt Accuracy:  633./ 960. (0.659375)\n",
      "Corrupt Val Base Accuracy:  527./ 960. (0.5489583333333333)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 1 corruption = frost\n",
      "Epoch 0\n",
      "Baseline Correct: 30002./48960. (61.28 %)\n",
      "Adapted Correct: 31625./48960. (64.59 %)\n",
      "Baseline Epoch Correct: 30002./48960. (61.28 %)\n",
      "Adapted Epoch Correct: 31625./48960. (64.59 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 60010./97920. (61.28 %)\n",
      "Adapted Correct: 63593./97920. (64.94 %)\n",
      "Baseline Epoch Correct: 30008./48960. (61.29 %)\n",
      "Adapted Epoch Correct: 31968./48960. (65.29 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 90003./146880. (61.28 %)\n",
      "Adapted Correct: 95792./146880. (65.22 %)\n",
      "Baseline Epoch Correct: 29993./48960. (61.26 %)\n",
      "Adapted Epoch Correct: 32199./48960. (65.77 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 120007./195840. (61.28 %)\n",
      "Adapted Correct: 128141./195840. (65.43 %)\n",
      "Baseline Epoch Correct: 30004./48960. (61.28 %)\n",
      "Adapted Epoch Correct: 32349./48960. (66.07 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 150013./244800. (61.28 %)\n",
      "Adapted Correct: 160511./244800. (65.57 %)\n",
      "Baseline Epoch Correct: 30006./48960. (61.29 %)\n",
      "Adapted Epoch Correct: 32370./48960. (66.12 %)\n",
      "Corrupt Val Adapt Accuracy:  654./ 960. (0.68125)\n",
      "Corrupt Val Base Accuracy:  598./ 960. (0.6229166666666667)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 1 corruption = fog\n",
      "Epoch 0\n",
      "Baseline Correct: 30274./48960. (61.83 %)\n",
      "Adapted Correct: 33700./48960. (68.83 %)\n",
      "Baseline Epoch Correct: 30274./48960. (61.83 %)\n",
      "Adapted Epoch Correct: 33700./48960. (68.83 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 60552./97920. (61.84 %)\n",
      "Adapted Correct: 67675./97920. (69.11 %)\n",
      "Baseline Epoch Correct: 30278./48960. (61.84 %)\n",
      "Adapted Epoch Correct: 33975./48960. (69.39 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 90827./146880. (61.84 %)\n",
      "Adapted Correct: 101740./146880. (69.27 %)\n",
      "Baseline Epoch Correct: 30275./48960. (61.84 %)\n",
      "Adapted Epoch Correct: 34065./48960. (69.58 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 121098./195840. (61.84 %)\n",
      "Adapted Correct: 136045./195840. (69.47 %)\n",
      "Baseline Epoch Correct: 30271./48960. (61.83 %)\n",
      "Adapted Epoch Correct: 34305./48960. (70.07 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 151366./244800. (61.83 %)\n",
      "Adapted Correct: 170316./244800. (69.57 %)\n",
      "Baseline Epoch Correct: 30268./48960. (61.82 %)\n",
      "Adapted Epoch Correct: 34271./48960. (70.00 %)\n",
      "Corrupt Val Adapt Accuracy:  659./ 960. (0.6864583333333333)\n",
      "Corrupt Val Base Accuracy:  583./ 960. (0.6072916666666667)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 2 corruption = snow\n",
      "Epoch 0\n",
      "Baseline Correct: 15610./48960. (31.88 %)\n",
      "Adapted Correct: 23374./48960. (47.74 %)\n",
      "Baseline Epoch Correct: 15610./48960. (31.88 %)\n",
      "Adapted Epoch Correct: 23374./48960. (47.74 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 31221./97920. (31.88 %)\n",
      "Adapted Correct: 47736./97920. (48.75 %)\n",
      "Baseline Epoch Correct: 15611./48960. (31.89 %)\n",
      "Adapted Epoch Correct: 24362./48960. (49.76 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 46833./146880. (31.89 %)\n",
      "Adapted Correct: 73004./146880. (49.70 %)\n",
      "Baseline Epoch Correct: 15612./48960. (31.89 %)\n",
      "Adapted Epoch Correct: 25268./48960. (51.61 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 62449./195840. (31.89 %)\n",
      "Adapted Correct: 98829./195840. (50.46 %)\n",
      "Baseline Epoch Correct: 15616./48960. (31.90 %)\n",
      "Adapted Epoch Correct: 25825./48960. (52.75 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 78056./244800. (31.89 %)\n",
      "Adapted Correct: 125174./244800. (51.13 %)\n",
      "Baseline Epoch Correct: 15607./48960. (31.88 %)\n",
      "Adapted Epoch Correct: 26345./48960. (53.81 %)\n",
      "Corrupt Val Adapt Accuracy:  527./ 960. (0.5489583333333333)\n",
      "Corrupt Val Base Accuracy:  330./ 960. (0.34375)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 2 corruption = frost\n",
      "Epoch 0\n",
      "Baseline Correct: 21610./48960. (44.14 %)\n",
      "Adapted Correct: 25371./48960. (51.82 %)\n",
      "Baseline Epoch Correct: 21610./48960. (44.14 %)\n",
      "Adapted Epoch Correct: 25371./48960. (51.82 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 43217./97920. (44.14 %)\n",
      "Adapted Correct: 51478./97920. (52.57 %)\n",
      "Baseline Epoch Correct: 21607./48960. (44.13 %)\n",
      "Adapted Epoch Correct: 26107./48960. (53.32 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 64826./146880. (44.14 %)\n",
      "Adapted Correct: 78193./146880. (53.24 %)\n",
      "Baseline Epoch Correct: 21609./48960. (44.14 %)\n",
      "Adapted Epoch Correct: 26715./48960. (54.56 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 86431./195840. (44.13 %)\n",
      "Adapted Correct: 105320./195840. (53.78 %)\n",
      "Baseline Epoch Correct: 21605./48960. (44.13 %)\n",
      "Adapted Epoch Correct: 27127./48960. (55.41 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 108035./244800. (44.13 %)\n",
      "Adapted Correct: 132717./244800. (54.21 %)\n",
      "Baseline Epoch Correct: 21604./48960. (44.13 %)\n",
      "Adapted Epoch Correct: 27397./48960. (55.96 %)\n",
      "Corrupt Val Adapt Accuracy:  540./ 960. (0.5625)\n",
      "Corrupt Val Base Accuracy:  418./ 960. (0.4354166666666667)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 2 corruption = fog\n",
      "Epoch 0\n",
      "Baseline Correct: 27361./48960. (55.88 %)\n",
      "Adapted Correct: 32500./48960. (66.38 %)\n",
      "Baseline Epoch Correct: 27361./48960. (55.88 %)\n",
      "Adapted Epoch Correct: 32500./48960. (66.38 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 54714./97920. (55.88 %)\n",
      "Adapted Correct: 65320./97920. (66.71 %)\n",
      "Baseline Epoch Correct: 27353./48960. (55.87 %)\n",
      "Adapted Epoch Correct: 32820./48960. (67.03 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 82072./146880. (55.88 %)\n",
      "Adapted Correct: 98416./146880. (67.00 %)\n",
      "Baseline Epoch Correct: 27358./48960. (55.88 %)\n",
      "Adapted Epoch Correct: 33096./48960. (67.60 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 109429./195840. (55.88 %)\n",
      "Adapted Correct: 131707./195840. (67.25 %)\n",
      "Baseline Epoch Correct: 27357./48960. (55.88 %)\n",
      "Adapted Epoch Correct: 33291./48960. (68.00 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 136784./244800. (55.88 %)\n",
      "Adapted Correct: 165152./244800. (67.46 %)\n",
      "Baseline Epoch Correct: 27355./48960. (55.87 %)\n",
      "Adapted Epoch Correct: 33445./48960. (68.31 %)\n",
      "Corrupt Val Adapt Accuracy:  685./ 960. (0.7135416666666666)\n",
      "Corrupt Val Base Accuracy:  542./ 960. (0.5645833333333333)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 3 corruption = snow\n",
      "Epoch 0\n",
      "Baseline Correct: 17218./48960. (35.17 %)\n",
      "Adapted Correct: 23720./48960. (48.45 %)\n",
      "Baseline Epoch Correct: 17218./48960. (35.17 %)\n",
      "Adapted Epoch Correct: 23720./48960. (48.45 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 34442./97920. (35.17 %)\n",
      "Adapted Correct: 48637./97920. (49.67 %)\n",
      "Baseline Epoch Correct: 17224./48960. (35.18 %)\n",
      "Adapted Epoch Correct: 24917./48960. (50.89 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 51668./146880. (35.18 %)\n",
      "Adapted Correct: 74271./146880. (50.57 %)\n",
      "Baseline Epoch Correct: 17226./48960. (35.18 %)\n",
      "Adapted Epoch Correct: 25634./48960. (52.36 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 68886./195840. (35.17 %)\n",
      "Adapted Correct: 100489./195840. (51.31 %)\n",
      "Baseline Epoch Correct: 17218./48960. (35.17 %)\n",
      "Adapted Epoch Correct: 26218./48960. (53.55 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 86103./244800. (35.17 %)\n",
      "Adapted Correct: 127066./244800. (51.91 %)\n",
      "Baseline Epoch Correct: 17217./48960. (35.17 %)\n",
      "Adapted Epoch Correct: 26577./48960. (54.28 %)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt Val Adapt Accuracy:  535./ 960. (0.5572916666666666)\n",
      "Corrupt Val Base Accuracy:  354./ 960. (0.36875)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 3 corruption = frost\n",
      "Epoch 0\n",
      "Baseline Correct: 15719./48960. (32.11 %)\n",
      "Adapted Correct: 20703./48960. (42.29 %)\n",
      "Baseline Epoch Correct: 15719./48960. (32.11 %)\n",
      "Adapted Epoch Correct: 20703./48960. (42.29 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 31441./97920. (32.11 %)\n",
      "Adapted Correct: 42305./97920. (43.20 %)\n",
      "Baseline Epoch Correct: 15722./48960. (32.11 %)\n",
      "Adapted Epoch Correct: 21602./48960. (44.12 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 47162./146880. (32.11 %)\n",
      "Adapted Correct: 64514./146880. (43.92 %)\n",
      "Baseline Epoch Correct: 15721./48960. (32.11 %)\n",
      "Adapted Epoch Correct: 22209./48960. (45.36 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 62887./195840. (32.11 %)\n",
      "Adapted Correct: 87258./195840. (44.56 %)\n",
      "Baseline Epoch Correct: 15725./48960. (32.12 %)\n",
      "Adapted Epoch Correct: 22744./48960. (46.45 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 78607./244800. (32.11 %)\n",
      "Adapted Correct: 110501./244800. (45.14 %)\n",
      "Baseline Epoch Correct: 15720./48960. (32.11 %)\n",
      "Adapted Epoch Correct: 23243./48960. (47.47 %)\n",
      "Corrupt Val Adapt Accuracy:  478./ 960. (0.4979166666666667)\n",
      "Corrupt Val Base Accuracy:  323./ 960. (0.33645833333333336)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 3 corruption = fog\n",
      "Epoch 0\n",
      "Baseline Correct: 22830./48960. (46.63 %)\n",
      "Adapted Correct: 30510./48960. (62.32 %)\n",
      "Baseline Epoch Correct: 22830./48960. (46.63 %)\n",
      "Adapted Epoch Correct: 30510./48960. (62.32 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 45658./97920. (46.63 %)\n",
      "Adapted Correct: 61557./97920. (62.86 %)\n",
      "Baseline Epoch Correct: 22828./48960. (46.63 %)\n",
      "Adapted Epoch Correct: 31047./48960. (63.41 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 68490./146880. (46.63 %)\n",
      "Adapted Correct: 93035./146880. (63.34 %)\n",
      "Baseline Epoch Correct: 22832./48960. (46.63 %)\n",
      "Adapted Epoch Correct: 31478./48960. (64.29 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 91319./195840. (46.63 %)\n",
      "Adapted Correct: 124806./195840. (63.73 %)\n",
      "Baseline Epoch Correct: 22829./48960. (46.63 %)\n",
      "Adapted Epoch Correct: 31771./48960. (64.89 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 114146./244800. (46.63 %)\n",
      "Adapted Correct: 156792./244800. (64.05 %)\n",
      "Baseline Epoch Correct: 22827./48960. (46.62 %)\n",
      "Adapted Epoch Correct: 31986./48960. (65.33 %)\n",
      "Corrupt Val Adapt Accuracy:  672./ 960. (0.7)\n",
      "Corrupt Val Base Accuracy:  457./ 960. (0.47604166666666664)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 4 corruption = snow\n",
      "Epoch 0\n",
      "Baseline Correct: 11789./48960. (24.08 %)\n",
      "Adapted Correct: 19202./48960. (39.22 %)\n",
      "Baseline Epoch Correct: 11789./48960. (24.08 %)\n",
      "Adapted Epoch Correct: 19202./48960. (39.22 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 23580./97920. (24.08 %)\n",
      "Adapted Correct: 39797./97920. (40.64 %)\n",
      "Baseline Epoch Correct: 11791./48960. (24.08 %)\n",
      "Adapted Epoch Correct: 20595./48960. (42.06 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 35374./146880. (24.08 %)\n",
      "Adapted Correct: 61331./146880. (41.76 %)\n",
      "Baseline Epoch Correct: 11794./48960. (24.09 %)\n",
      "Adapted Epoch Correct: 21534./48960. (43.98 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 47164./195840. (24.08 %)\n",
      "Adapted Correct: 83605./195840. (42.69 %)\n",
      "Baseline Epoch Correct: 11790./48960. (24.08 %)\n",
      "Adapted Epoch Correct: 22274./48960. (45.49 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 58954./244800. (24.08 %)\n",
      "Adapted Correct: 106466./244800. (43.49 %)\n",
      "Baseline Epoch Correct: 11790./48960. (24.08 %)\n",
      "Adapted Epoch Correct: 22861./48960. (46.69 %)\n",
      "Corrupt Val Adapt Accuracy:  423./ 960. (0.440625)\n",
      "Corrupt Val Base Accuracy:  220./ 960. (0.22916666666666666)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 4 corruption = frost\n",
      "Epoch 0\n",
      "Baseline Correct: 14641./48960. (29.90 %)\n",
      "Adapted Correct: 19913./48960. (40.67 %)\n",
      "Baseline Epoch Correct: 14641./48960. (29.90 %)\n",
      "Adapted Epoch Correct: 19913./48960. (40.67 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 29292./97920. (29.91 %)\n",
      "Adapted Correct: 40862./97920. (41.73 %)\n",
      "Baseline Epoch Correct: 14651./48960. (29.92 %)\n",
      "Adapted Epoch Correct: 20949./48960. (42.79 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 43942./146880. (29.92 %)\n",
      "Adapted Correct: 62399./146880. (42.48 %)\n",
      "Baseline Epoch Correct: 14650./48960. (29.92 %)\n",
      "Adapted Epoch Correct: 21537./48960. (43.99 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 58592./195840. (29.92 %)\n",
      "Adapted Correct: 84433./195840. (43.11 %)\n",
      "Baseline Epoch Correct: 14650./48960. (29.92 %)\n",
      "Adapted Epoch Correct: 22034./48960. (45.00 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 73236./244800. (29.92 %)\n",
      "Adapted Correct: 106863./244800. (43.65 %)\n",
      "Baseline Epoch Correct: 14644./48960. (29.91 %)\n",
      "Adapted Epoch Correct: 22430./48960. (45.81 %)\n",
      "Corrupt Val Adapt Accuracy:  433./ 960. (0.4510416666666667)\n",
      "Corrupt Val Base Accuracy:  277./ 960. (0.28854166666666664)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 4 corruption = fog\n",
      "Epoch 0\n",
      "Baseline Correct: 19811./48960. (40.46 %)\n",
      "Adapted Correct: 29107./48960. (59.45 %)\n",
      "Baseline Epoch Correct: 19811./48960. (40.46 %)\n",
      "Adapted Epoch Correct: 29107./48960. (59.45 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 39616./97920. (40.46 %)\n",
      "Adapted Correct: 58943./97920. (60.20 %)\n",
      "Baseline Epoch Correct: 19805./48960. (40.45 %)\n",
      "Adapted Epoch Correct: 29836./48960. (60.94 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 59426./146880. (40.46 %)\n",
      "Adapted Correct: 89170./146880. (60.71 %)\n",
      "Baseline Epoch Correct: 19810./48960. (40.46 %)\n",
      "Adapted Epoch Correct: 30227./48960. (61.74 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 79226./195840. (40.45 %)\n",
      "Adapted Correct: 119839./195840. (61.19 %)\n",
      "Baseline Epoch Correct: 19800./48960. (40.44 %)\n",
      "Adapted Epoch Correct: 30669./48960. (62.64 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 99038./244800. (40.46 %)\n",
      "Adapted Correct: 150729./244800. (61.57 %)\n",
      "Baseline Epoch Correct: 19812./48960. (40.47 %)\n",
      "Adapted Epoch Correct: 30890./48960. (63.09 %)\n",
      "Corrupt Val Adapt Accuracy:  607./ 960. (0.6322916666666667)\n",
      "Corrupt Val Base Accuracy:  365./ 960. (0.3802083333333333)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 5 corruption = snow\n",
      "Epoch 0\n",
      "Baseline Correct: 8267./48960. (16.89 %)\n",
      "Adapted Correct: 17810./48960. (36.38 %)\n",
      "Baseline Epoch Correct: 8267./48960. (16.89 %)\n",
      "Adapted Epoch Correct: 17810./48960. (36.38 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 16534./97920. (16.89 %)\n",
      "Adapted Correct: 37036./97920. (37.82 %)\n",
      "Baseline Epoch Correct: 8267./48960. (16.89 %)\n",
      "Adapted Epoch Correct: 19226./48960. (39.27 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 24796./146880. (16.88 %)\n",
      "Adapted Correct: 57384./146880. (39.07 %)\n",
      "Baseline Epoch Correct: 8262./48960. (16.88 %)\n",
      "Adapted Epoch Correct: 20348./48960. (41.56 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 33061./195840. (16.88 %)\n",
      "Adapted Correct: 78568./195840. (40.12 %)\n",
      "Baseline Epoch Correct: 8265./48960. (16.88 %)\n",
      "Adapted Epoch Correct: 21184./48960. (43.27 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 41330./244800. (16.88 %)\n",
      "Adapted Correct: 100436./244800. (41.03 %)\n",
      "Baseline Epoch Correct: 8269./48960. (16.89 %)\n",
      "Adapted Epoch Correct: 21868./48960. (44.67 %)\n",
      "Corrupt Val Adapt Accuracy:  460./ 960. (0.4791666666666667)\n",
      "Corrupt Val Base Accuracy:  165./ 960. (0.171875)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 5 corruption = frost\n",
      "Epoch 0\n",
      "Baseline Correct: 11414./48960. (23.31 %)\n",
      "Adapted Correct: 16955./48960. (34.63 %)\n",
      "Baseline Epoch Correct: 11414./48960. (23.31 %)\n",
      "Adapted Epoch Correct: 16955./48960. (34.63 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 22836./97920. (23.32 %)\n",
      "Adapted Correct: 34900./97920. (35.64 %)\n",
      "Baseline Epoch Correct: 11422./48960. (23.33 %)\n",
      "Adapted Epoch Correct: 17945./48960. (36.65 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 34253./146880. (23.32 %)\n",
      "Adapted Correct: 53579./146880. (36.48 %)\n",
      "Baseline Epoch Correct: 11417./48960. (23.32 %)\n",
      "Adapted Epoch Correct: 18679./48960. (38.15 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 45677./195840. (23.32 %)\n",
      "Adapted Correct: 72882./195840. (37.22 %)\n",
      "Baseline Epoch Correct: 11424./48960. (23.33 %)\n",
      "Adapted Epoch Correct: 19303./48960. (39.43 %)\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Correct: 57096./244800. (23.32 %)\n",
      "Adapted Correct: 92579./244800. (37.82 %)\n",
      "Baseline Epoch Correct: 11419./48960. (23.32 %)\n",
      "Adapted Epoch Correct: 19697./48960. (40.23 %)\n",
      "Corrupt Val Adapt Accuracy:  365./ 960. (0.3802083333333333)\n",
      "Corrupt Val Base Accuracy:  217./ 960. (0.22604166666666667)\n",
      "===================================================================================================\n",
      "Running experiment for severity = 5 corruption = fog\n",
      "Epoch 0\n",
      "Baseline Correct: 11942./48960. (24.39 %)\n",
      "Adapted Correct: 24478./48960. (50.00 %)\n",
      "Baseline Epoch Correct: 11942./48960. (24.39 %)\n",
      "Adapted Epoch Correct: 24478./48960. (50.00 %)\n",
      "Epoch 1\n",
      "Baseline Correct: 23892./97920. (24.40 %)\n",
      "Adapted Correct: 50369./97920. (51.44 %)\n",
      "Baseline Epoch Correct: 11950./48960. (24.41 %)\n",
      "Adapted Epoch Correct: 25891./48960. (52.88 %)\n",
      "Epoch 2\n",
      "Baseline Correct: 35841./146880. (24.40 %)\n",
      "Adapted Correct: 77110./146880. (52.50 %)\n",
      "Baseline Epoch Correct: 11949./48960. (24.41 %)\n",
      "Adapted Epoch Correct: 26741./48960. (54.62 %)\n",
      "Epoch 3\n",
      "Baseline Correct: 47786./195840. (24.40 %)\n",
      "Adapted Correct: 104409./195840. (53.31 %)\n",
      "Baseline Epoch Correct: 11945./48960. (24.40 %)\n",
      "Adapted Epoch Correct: 27299./48960. (55.76 %)\n",
      "Epoch 4\n",
      "Baseline Correct: 59727./244800. (24.40 %)\n",
      "Adapted Correct: 132152./244800. (53.98 %)\n",
      "Baseline Epoch Correct: 11941./48960. (24.39 %)\n",
      "Adapted Epoch Correct: 27743./48960. (56.66 %)\n",
      "Corrupt Val Adapt Accuracy:  549./ 960. (0.571875)\n",
      "Corrupt Val Base Accuracy:  249./ 960. (0.259375)\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for severity in range(1, 6):\n",
    "\n",
    "    ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption \\\n",
    "            = get_imagenetc(imagebase, severity, batch_size, 49000)\n",
    "    \n",
    "    for cor in weather[1:]:\n",
    "    \n",
    "        print(\"Running experiment for severity =\", severity, \"corruption =\", cor)\n",
    "        \n",
    "#         start = time.time()\n",
    "        base_acc, base_acc_epoch, adapted_train_acc_overall, adapted_train_acc_per_epoch, \\\n",
    "            adapted_train_acc_per_iter, model, baseline, training_time = evaluate(corrupted_dataloaders[corruption.index(cor)]['train'])\n",
    "#         adapt_time = time.time() - start\n",
    "\n",
    "        base_cum_acc[severity-1][corruption.index(cor)] = base_acc_epoch[0]\n",
    "        adapted_cum_acc[severity-1][corruption.index(cor)] = adapted_train_acc_overall[-1]\n",
    "\n",
    "        ## evaluate on validation set\n",
    "        model.eval()\n",
    "        baseline.eval()\n",
    "        with torch.no_grad():\n",
    "            base_val_correct, crpt_val_correct, crpt_val_samples = 0, 0, 0\n",
    "            for images, labels in corrupted_dataloaders[corruption.index(cor)]['val']:\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                crpt_val_correct += (predicted == labels).sum().item()\n",
    "                crpt_val_samples += len(labels)\n",
    "\n",
    "                b_outputs = baseline(images.to(device))\n",
    "                _, b_predicted = torch.max(b_outputs.data, 1)\n",
    "                base_val_correct += (b_predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        print(f\"Corrupt Val Adapt Accuracy: {crpt_val_correct:#5.0f}/{crpt_val_samples:#5.0f} ({crpt_val_correct / crpt_val_samples})\")\n",
    "        print(f\"Corrupt Val Base Accuracy: {base_val_correct:#5.0f}/{crpt_val_samples:#5.0f} ({base_val_correct / crpt_val_samples})\")\n",
    "\n",
    "        acc_record_sev[severity][cor] = [base_acc, base_acc_epoch, adapted_train_acc_overall, adapted_train_acc_per_epoch, \\\n",
    "                                    adapted_train_acc_per_iter, (base_val_correct / crpt_val_samples), \\\n",
    "                                    (crpt_val_correct / crpt_val_samples), training_time]\n",
    "\n",
    "        print(\"===================================================================================================\")\n",
    "        \n",
    "        with open('BASE_cum_acc_replicate.npy', 'wb') as f:\n",
    "            np.save(f, base_cum_acc)\n",
    "        with open('RPL_cum_acc_replicate.npy', 'wb') as f:\n",
    "            np.save(f, adapted_cum_acc)\n",
    "            \n",
    "        with open('PERFORMANCE_dic_replicate.pkl', 'wb') as f:\n",
    "            pickle.dump(acc_record_sev, f)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1479f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('BASE_cum_acc_replicate.npy', 'rb') as f:\n",
    "#     np.save(f, base_cum_acc)\n",
    "    base_cum_acc = np.load(f)\n",
    "with open('RPL_cum_acc_replicate.npy', 'rb') as f:\n",
    "#     np.save(f, adapted_cum_acc)\n",
    "    adapted_cum_acc = np.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ae8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## running the original experiment using the paper hyperparams\n",
    "\n",
    "base_cum_acc = np.zeros((5, len(corruption)))\n",
    "adapted_cum_acc = np.zeros((5, len(corruption)))\n",
    "\n",
    "\n",
    "acc_record_sev = {}\n",
    "batch_size = 96\n",
    "\n",
    "for severity in range(1, 6):\n",
    "    \n",
    "    acc_record_sev[severity] = {}\n",
    "\n",
    "for severity in range(1, 6):\n",
    "\n",
    "    ref_dataloaders, ref_dataset_sizes, corrupted_dataloaders, corrupted_dataset_sizes, corruption \\\n",
    "            = get_imagenetc(imagebase, severity, batch_size, 49000)\n",
    "    \n",
    "    for cor in weather[1:]:\n",
    "    \n",
    "        print(\"Running experiment for severity =\", severity, \"corruption =\", cor)\n",
    "        \n",
    "#         start = time.time()\n",
    "        base_acc, base_acc_epoch, adapted_train_acc_overall, adapted_train_acc_per_epoch, \\\n",
    "            adapted_train_acc_per_iter, model, baseline, training_time = evaluate(corrupted_dataloaders[corruption.index(cor)]['train'])\n",
    "#         adapt_time = time.time() - start\n",
    "\n",
    "        base_cum_acc[severity-1][corruption.index(cor)] = base_acc_epoch[0]\n",
    "        adapted_cum_acc[severity-1][corruption.index(cor)] = adapted_train_acc_overall[-1]\n",
    "\n",
    "        ## evaluate on validation set\n",
    "        model.eval()\n",
    "        baseline.eval()\n",
    "        with torch.no_grad():\n",
    "            base_val_correct, crpt_val_correct, crpt_val_samples = 0, 0, 0\n",
    "            for images, labels in corrupted_dataloaders[corruption.index(cor)]['val']:\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(images.to(device))\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                crpt_val_correct += (predicted == labels).sum().item()\n",
    "                crpt_val_samples += len(labels)\n",
    "\n",
    "                b_outputs = baseline(images.to(device))\n",
    "                _, b_predicted = torch.max(b_outputs.data, 1)\n",
    "                base_val_correct += (b_predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "        print(f\"Corrupt Val Adapt Accuracy: {crpt_val_correct:#5.0f}/{crpt_val_samples:#5.0f} ({crpt_val_correct / crpt_val_samples})\")\n",
    "        print(f\"Corrupt Val Base Accuracy: {base_val_correct:#5.0f}/{crpt_val_samples:#5.0f} ({base_val_correct / crpt_val_samples})\")\n",
    "\n",
    "        acc_record_sev[severity][cor] = [base_acc, base_acc_epoch, adapted_train_acc_overall, adapted_train_acc_per_epoch, \\\n",
    "                                    adapted_train_acc_per_iter, (base_val_correct / crpt_val_samples), \\\n",
    "                                    (crpt_val_correct / crpt_val_samples), training_time]\n",
    "\n",
    "        print(\"===================================================================================================\")\n",
    "        \n",
    "        with open('BASE_cum_acc_replicate.npy', 'wb') as f:\n",
    "            np.save(f, base_cum_acc)\n",
    "        with open('RPL_cum_acc_replicate.npy', 'wb') as f:\n",
    "            np.save(f, adapted_cum_acc)\n",
    "            \n",
    "        with open('PERFORMANCE_dic_replicate.pkl', 'wb') as f:\n",
    "            pickle.dump(acc_record_sev, f)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open('BASE_cum_acc_replicate.npy', 'rb') as f:\n",
    "#     np.save(f, base_cum_acc)\n",
    "    base_cum_acc = np.load(f)\n",
    "with open('RPL_cum_acc_replicate.npy', 'rb') as f:\n",
    "#     np.save(f, adapted_cum_acc)\n",
    "    adapted_cum_acc = np.load(f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
